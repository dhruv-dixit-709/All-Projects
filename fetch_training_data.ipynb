{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import operator\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cornell Movie Dialogues Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the Cornell Movie Dialogues data\n",
    "f = open('movie_lines.txt', 'r')\n",
    "lines = f.read().split('\\n')\n",
    "dic = {}\n",
    "for line in lines:\n",
    "    if len(line.split('+++$+++')) > 4:\n",
    "        dic[int(line.split()[0][1:])] = line.split('+++$+++')[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the dialogues into the proper sequence based on the line number 'L.....' in the dataset\n",
    "lst = sorted(dic.items(), key = operator.itemgetter(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the queries and replies into different batches; based on the films in the dataset\n",
    "batches = {}\n",
    "count = 1\n",
    "batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(lst) + 1):\n",
    "    if i < len(lst):\n",
    "        if lst[i][0] == lst[i-1][0] + 1:\n",
    "            if lst[i-1][1][0].lstrip() not in batch : \n",
    "                batch.append(lst[i-1][1][0].lstrip()) \n",
    "            batch.append(lst[i][1][0].lstrip()) \n",
    "        else:\n",
    "            batches[count] = batch\n",
    "            batch = []\n",
    "        count+=1\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data into context and target pairs\n",
    "context_and_target = []\n",
    "for ls in batches.values():\n",
    "    if len(ls)%2!=0: ls = ls[:-1]\n",
    "    for i in range(0, len(ls), 2):\n",
    "        context_and_target.append((ls[i], ls[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context, target = zip(*context_and_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = list(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos,i in enumerate(target):\n",
    "    target[pos] = re.sub('[^a-zA-Z0-9 .,?!]', '', i)\n",
    "    target[pos] = re.sub(' +', ' ', i)\n",
    "    target[pos] = re.sub('([\\w]+)([,;.?!#&-\\'\\\"-]+)([\\w]+)?', r'\\1 \\2 \\3', i)\n",
    "    if len(i.split()) > maxlen:\n",
    "        target[pos] = (' ').join(target[pos].split()[:maxlen])\n",
    "        if '.' in target[pos]: \n",
    "            ind = target[pos].index('.')\n",
    "            target[pos] = target[pos][:ind+1]\n",
    "        if '?' in target[pos]:\n",
    "            ind = target[pos].index('?')\n",
    "            target[pos] = target[pos][:ind+1]\n",
    "        if '!' in target[pos]:\n",
    "            ind = target[pos].index('!')\n",
    "            target[pos] = target[pos][:ind+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = list(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos,i in enumerate(context):\n",
    "    context[pos] = re.sub('[^a-zA-Z0-9 .,?!]', '', i)\n",
    "    context[pos] = re.sub(' +', ' ', i)\n",
    "    context[pos] = re.sub('([\\w]+)([,;.?!#&\\'\\\"-]+)([\\w]+)?', r'\\1 \\2 \\3', i)\n",
    "    if len(i.split()) > maxlen:\n",
    "            context[pos] = (' ').join(context[pos].split()[:maxlen])\n",
    "            if '.' in context[pos]:\n",
    "                ind = context[pos].index('.')\n",
    "                context[pos] = context[pos][:ind+1]\n",
    "            if '?' in context[pos]:\n",
    "                ind = context[pos].index('?')\n",
    "                context[pos] = context[pos][:ind+1]\n",
    "            if '!' in context[pos]:\n",
    "                ind = context[pos].index('!')\n",
    "                context[pos] = context[pos][:ind+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Beginning of Sentence (BOS) and End of Sentence (EOS) tags to the 'target' data\n",
    "final_target = ['BOS ' + i + ' EOS' for i in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any extra spaces\n",
    "final_target = list(pd.Series(final_target).map(lambda x: re.sub(' +', ' ', x)))\n",
    "context = list(pd.Series(context).map(lambda x: re.sub(' +', ' ', x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique words in the dataset alongwith their counts\n",
    "counts = {}\n",
    "for words in final_target+context:\n",
    "    for word in words.split():\n",
    "        counts[word] = counts.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dictionary mapping words to indexes\n",
    "word_to_index = {}\n",
    "for pos,i in enumerate(counts.keys()):\n",
    "    word_to_index[i] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse dictionary mapping indexes to words\n",
    "index_to_word = {}\n",
    "for k,v in word_to_index.items():\n",
    "    index_to_word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the dictionary to the context and target data\n",
    "final_target = np.array([[word_to_index[w] for w in i.split()] for i in final_target])\n",
    "context = np.array([[word_to_index[w] for w in i.split()] for i in context])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('context_indexes', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('target_indexes', final_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_index, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reverse_dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(index_to_word, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
